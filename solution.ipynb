{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Document Reference Extraction\n",
    "\n",
    "This notebook extracts and matches references to paragraphs, annexes, figures, and tables from legal document text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_loading",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation data: 941 paragraphs\n",
      "Paragraphs with references: 81\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>targetIds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Preamble</td>\n",
       "      <td>659d4ec2cbbf0962d357384e</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The World Forum for Harmonization of Vehicle R...</td>\n",
       "      <td>659d50422e63b7837a047b7c</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 TRANS/WP.29/1045 as amended by ECE/TRANS/WP....</td>\n",
       "      <td>659d50452e63b7837a047b84</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Introduction</td>\n",
       "      <td>659d501f2e63b7837a047b6b</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The text hereafter updates the recommendations...</td>\n",
       "      <td>659d50872e63b7837a047ba6</td>\n",
       "      <td>[659d4ec2cbbf0962d3573947, 659d4ec2cbbf0962d35...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                                           Preamble   \n",
       "1  The World Forum for Harmonization of Vehicle R...   \n",
       "2  1 TRANS/WP.29/1045 as amended by ECE/TRANS/WP....   \n",
       "3                                       Introduction   \n",
       "4  The text hereafter updates the recommendations...   \n",
       "\n",
       "                         id                                          targetIds  \n",
       "0  659d4ec2cbbf0962d357384e                                                 []  \n",
       "1  659d50422e63b7837a047b7c                                                 []  \n",
       "2  659d50452e63b7837a047b84                                                 []  \n",
       "3  659d501f2e63b7837a047b6b                                                 []  \n",
       "4  659d50872e63b7837a047ba6  [659d4ec2cbbf0962d3573947, 659d4ec2cbbf0962d35...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load evaluation and test data\n",
    "with open(\"evaluation_data.json\", \"r\") as f:\n",
    "    eval_data = json.load(f)\n",
    "\n",
    "with open(\"test_data.json\", \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "# Create DataFrames\n",
    "df_eval = pd.DataFrame(eval_data[\"paragraphLinks\"])\n",
    "df_test = pd.DataFrame(test_data[\"paragraphLinks\"])\n",
    "\n",
    "print(f\"Evaluation data: {len(df_eval)} paragraphs\")\n",
    "print(f\"Paragraphs with references: {df_eval['targetIds'].apply(lambda x: len(x) > 0).sum()}\")\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textual_id_extraction",
   "metadata": {},
   "source": [
    "## Textual ID Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "textual_id_functions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 625 textual ID mappings\n"
     ]
    }
   ],
   "source": [
    "def generate_textual_id(text: str) -> str:\n",
    "    \"\"\"Extract textual ID from paragraph text (e.g., 'paragraph 1.2.3.', 'Annex 4').\"\"\"\n",
    "    # Try paragraph numeric id at start (e.g., \"1.2.3. Some text...\" or \"1.2.3 Some text...\")\n",
    "    m = re.match(r'^(\\d+(?:\\.\\d+)*\\.?)(\\.|\\s)', text)\n",
    "    if m:\n",
    "        number_part = m.group(1)\n",
    "        # Ensure trailing dot is preserved\n",
    "        if not number_part.endswith('.'):\n",
    "            number_part += '.'\n",
    "        return f\"paragraph {number_part}\"\n",
    "    \n",
    "    # Try other label types at start (e.g., \"Annex 4\", \"Figure 1\")\n",
    "    for prefix in [\"Annex\", \"Figure\", \"Table\"]:\n",
    "        m = re.match(rf'^{prefix}\\s+[A-Z0-9]+', text, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            return m.group(0)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def build_textual_id_map(text_series: pd.Series, id_series: pd.Series) -> Dict[str, str]:\n",
    "    \"\"\"Build mapping from textual IDs to document IDs.\"\"\"\n",
    "    df_temp = pd.DataFrame({'text': text_series, 'id': id_series})\n",
    "    df_temp['textualId'] = df_temp['text'].apply(generate_textual_id)\n",
    "    df_filtered = df_temp[df_temp['textualId'].notnull()]\n",
    "    return dict(zip(df_filtered['textualId'], df_filtered['id']))\n",
    "\n",
    "# Create textual ID mapping\n",
    "df_eval['textualId'] = df_eval['text'].apply(generate_textual_id)\n",
    "textual_to_id = build_textual_id_map(df_eval[\"text\"], df_eval[\"id\"])\n",
    "print(f\"Created {len(textual_to_id)} textual ID mappings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reference_extraction",
   "metadata": {},
   "source": [
    "## Reference Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reference_extraction_functions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted references from 95 paragraphs\n"
     ]
    }
   ],
   "source": [
    "def extract_references(text: str) -> List[str]:\n",
    "    \"\"\"Extract references like 'paragraph 1.2', 'Annex 4', 'paragraphs 1.1 to 1.3'.\"\"\"\n",
    "    ref_types = r\"(?:annex|annexes|paragraph|paragraphs|section|sections|table|tables|figure|figures)\"\n",
    "    number_pattern = r\"\\d+(?:\\.\\d+)*\\.?\"\n",
    "\n",
    "    # Range pattern (e.g., \"paragraphs 4. to 7.\")\n",
    "    range_pattern = rf\"({ref_types})\\s+({number_pattern})\\s+((?:to|and)\\s+{number_pattern})\"\n",
    "    # Simple pattern (e.g., \"paragraph 1.2\")\n",
    "    simple_pattern = rf\"({ref_types})\\s+({number_pattern})\"\n",
    "\n",
    "    matches = []\n",
    "    range_positions = []\n",
    "\n",
    "    # Find paragraph range starts for subparagraph matching\n",
    "    paragraph_range_starts = set()\n",
    "    for match in re.finditer(range_pattern, text, re.IGNORECASE):\n",
    "        if match.start() == 0:  # Skip matches at text beginning\n",
    "            continue\n",
    "        matches.append(match.group(0))\n",
    "        range_positions.append((match.start(), match.end()))\n",
    "\n",
    "        ref_type = match.group(1).lower()\n",
    "        if \"paragraph\" in ref_type:\n",
    "            start_num = match.group(2).rstrip(\".\")\n",
    "            paragraph_range_starts.add(start_num)\n",
    "\n",
    "    # Find simple matches\n",
    "    for match in re.finditer(simple_pattern, text, re.IGNORECASE):\n",
    "        if match.start() == 0:  # Skip matches at text beginning\n",
    "            continue\n",
    "\n",
    "        # Skip overlaps with ranges\n",
    "        overlaps = any(\n",
    "            match.start() < end and match.end() > start\n",
    "            for start, end in range_positions\n",
    "        )\n",
    "        if overlaps:\n",
    "            continue\n",
    "\n",
    "        ref_type = match.group(1).lower()\n",
    "        number = match.group(2).rstrip(\".\")\n",
    "\n",
    "        # FIXED: For paragraphs, include all if no ranges, or only matching ones if ranges exist\n",
    "        if \"paragraph\" in ref_type:\n",
    "            if not paragraph_range_starts or any(number == start or number.startswith(start + \".\") for start in paragraph_range_starts):\n",
    "                matches.append(match.group(0))\n",
    "        else:\n",
    "            matches.append(match.group(0))\n",
    "\n",
    "    return matches\n",
    "# Apply reference extraction\n",
    "df_eval['references'] = df_eval['text'].apply(extract_references)\n",
    "print(f\"Extracted references from {df_eval['references'].apply(len).gt(0).sum()} paragraphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df5dbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>targetIds</th>\n",
       "      <th>textualId</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, id, targetIds, textualId, references]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval[df_eval['textualId'] == \"paragraph 2.5.1\"]\n",
    "# df_eval[df_eval['references'].apply(lambda refs: \"paragraph 2.5.1\" in refs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reference_matching",
   "metadata": {},
   "source": [
    "## Reference Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reference_matching_functions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated predictions for 941 paragraphs\n"
     ]
    }
   ],
   "source": [
    "def is_section_in_range(section: str, start: str, end: str) -> bool:\n",
    "    \"\"\"Check if a section number is within a given range.\"\"\"\n",
    "    return start <= section <= end\n",
    "\n",
    "def find_matching_ids(references: List[str], key_to_id_dict: Dict[str, str]) -> List[str]:\n",
    "    \"\"\"Find matching document IDs for extracted references.\"\"\"\n",
    "    matching_ids = set()\n",
    "\n",
    "    for ref in references:\n",
    "        ref = ref.strip()\n",
    "\n",
    "        # Handle \"and\" pattern (e.g., \"Paragraphs 1. and 2.\")\n",
    "        and_match = re.search(r'(.+?)\\s+([\\d.]+)\\s+and\\s+([\\d.]+)', ref, re.IGNORECASE)\n",
    "        if and_match:\n",
    "            prefix = and_match.group(1).rstrip('s').strip()\n",
    "            for num in [and_match.group(2).rstrip('.'), and_match.group(3).rstrip('.')]:\n",
    "                key = f\"{prefix} {num}\"\n",
    "                if key in key_to_id_dict:\n",
    "                    matching_ids.add(key_to_id_dict[key])\n",
    "            continue\n",
    "\n",
    "        # Handle \"to\" pattern (e.g., \"paragraphs 4. to 7.\")\n",
    "        range_match = re.search(r'(.+?)\\s+([\\d.]+)\\s+to\\s+([\\d.]+)', ref, re.IGNORECASE)\n",
    "        if range_match:\n",
    "            prefix = range_match.group(1).rstrip('s').strip()\n",
    "            start = range_match.group(2).rstrip('.')\n",
    "            end = range_match.group(3).rstrip('.')\n",
    "\n",
    "            # Find all matching keys in range\n",
    "            for key in key_to_id_dict:\n",
    "                key_match = re.match(rf'{prefix}\\s+([\\d.]+)', key, re.IGNORECASE)\n",
    "                if key_match:\n",
    "                    section = key_match.group(1)\n",
    "                    if is_section_in_range(section, start, end):\n",
    "                        matching_ids.add(key_to_id_dict[key])\n",
    "            continue\n",
    "\n",
    "        # Handle exact match\n",
    "        if ref in key_to_id_dict:\n",
    "            matching_ids.add(key_to_id_dict[ref])\n",
    "\n",
    "    return list(matching_ids)\n",
    "\n",
    "# Apply reference matching\n",
    "df_eval['targetIdsPredicted'] = df_eval['references'].apply(\n",
    "    lambda refs: find_matching_ids(refs, textual_to_id)\n",
    ")\n",
    "\n",
    "print(f\"Generated predictions for {len(df_eval)} paragraphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "evaluation_functions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.07%\n",
      "Recall: 95.38%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_accuracy_and_recall(df: pd.DataFrame) -> Dict[str, float]:\n",
    "    \"\"\"Calculate accuracy and recall metrics.\"\"\"\n",
    "    total_accuracy = 0\n",
    "    total_recall = 0\n",
    "    count = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        true_ids = set(row[\"targetIds\"])\n",
    "        pred_ids = set(row[\"targetIdsPredicted\"])\n",
    "\n",
    "        tp = len(true_ids & pred_ids)\n",
    "        fp = len(pred_ids - true_ids)\n",
    "        fn = len(true_ids - pred_ids)\n",
    "\n",
    "        # Calculate metrics\n",
    "        denom_accuracy = tp + fp + fn\n",
    "        denom_recall = tp + fn\n",
    "\n",
    "        row_accuracy = tp / denom_accuracy if denom_accuracy > 0 else 1.0\n",
    "        row_recall = tp / denom_recall if denom_recall > 0 else 1.0\n",
    "\n",
    "        total_accuracy += row_accuracy\n",
    "        total_recall += row_recall\n",
    "        count += 1\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": total_accuracy / count if count > 0 else 0,\n",
    "        \"recall\": total_recall / count if count > 0 else 0\n",
    "    }\n",
    "\n",
    "# Evaluate results\n",
    "metrics = evaluate_accuracy_and_recall(df_eval)\n",
    "print(f\"Accuracy: {metrics['accuracy']:.2%}\")\n",
    "print(f\"Recall: {metrics['recall']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error_analysis",
   "metadata": {},
   "source": [
    "## Error Analysis (Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "error_analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Row 4 ---\n",
      "Text: The text hereafter updates the recommendations of the Consolidated Resolution on the Construction of Vehicles and provides information on the legal texts under the framework of the 1958 Agreement (UN \n",
      "References found: ['Paragraphs 1. and 2.', 'paragraphs 4. to 7.', 'Annex 3', 'Annex 4', 'Annex 5', 'Annex 6', 'Annex 7']\n",
      "❌ Missed (False Negatives):\n",
      "  - Annex 5: Annex 5 Design principles for Control Systems of Advanced Driver Assistance System (ADAS)...\n",
      "  - paragraph 8.: 8. Recommendations...\n",
      "❌ Incorrect Predictions (False Positives):\n",
      "  - paragraph 4.14.1.: 4.14.1. The coordinates of the \"H\" point are measured with respect to the three-dimensional reference system....\n",
      "  - paragraph 5.: 5. References Bainbridge, L. (1987). Ironies of Automation. In J. Rasmussen, K. Duncan, and J. Leplat (Eds.), New Technology and Human Error. Chichester and New York: John Wiley & Sons. Brook-Carter, N. & Parkes, A. (2000). ADAS and Driver Behavioural Adaptation. European Community: Competitive and Sustainable Growth Programme. Endsley, M.R. & Kiris, E.O. (1995). The out-of-the-loop performance problem and level of control in automation. Human Factors, 37(2), 381-94. Flemisch, F., Kelsch, J., Löper, C., Schieben, A., & Schindler, J. (2008). Automation spectrum, inner / outer compatibility and other potentially useful human factors concepts for assistance and automation. In D. de Waard, F.O. Flemisch, B. Lorenz, H. Oberheid, and K.A. Brookhuis (Eds.) (2008), Human Factors for assistance and automation (pp. 1 - 16). Maastricht, the Netherlands: Shaker Publishing. Hiramatsu, K. (2005). International Harmonized Research Activities – Intelligent Transport Sytems (IHRA – ITS) Working Group R...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Row 80 ---\n",
      "Text: 2.8.1. Definition. Off-road vehicles are considered to be the vehicles of categories M and N satisfying the requirements of this paragraph, checked under the conditions indicated in paragraphs 2.8.2. \n",
      "References found: ['paragraphs 2.8.2. and 2.8.3.']\n",
      "❌ Missed (False Negatives):\n",
      "  - paragraph 2.8.2.: 2.8.2. Load and checking conditions...\n",
      "  - paragraph 2.8.3.: 2.8.3. Definitions and sketches of front and rear incidence angles, ramp angle and ground clearance....\n",
      "\n",
      "--- Row 86 ---\n",
      "Text: 2.8.2.2. Power-driven vehicles other than those referred to in paragraph 2.8.2.1. shall be loaded to the technically permissible maximum mass stated by the manufacturer.\n",
      "References found: ['paragraph 2.8.2.1.']\n",
      "❌ Incorrect Predictions (False Positives):\n",
      "  - paragraph 2.8.2.1.: 2.8.2.1. Vehicles in category N1 with a maximum mass not exceeding 2,000 kg and vehicles in category M1 shall be in running order, namely with coolant fluid, lubricants, fuel, tools, spare-wheel and a driver considered to weigh a standard 75 kg....\n",
      "\n",
      "--- Row 278 ---\n",
      "Text: The table below contains the requirements or a group of requirements in the field of active safety, already adopted by the World Forum and included into UN Regulations. For any requirement or group of\n",
      "References found: ['paragraphs 8.1. to 8.3.2.', 'paragraphs 8.1. to 8.3.2.', 'Annex 2']\n",
      "❌ Missed (False Negatives):\n",
      "  - paragraph 8.4.: 8.4. Audible signals of cycles...\n",
      "  - paragraph 8.3.2.: 8.3.2. Users' associations should draw the attention of vehicle users to the dangers of using unsuit...\n",
      "❌ Incorrect Predictions (False Positives):\n",
      "  - paragraph 8.16.11.: 8.16.11. In the case of tank-vehicles, where outrigger brackets are used to fasten the tank to the chassis of the vehicle, the vertical face of the brackets shall not be less in height than the depth of the chassis frame to which they are attached....\n",
      "  - paragraph 8.16.12.: 8.16.12. In the case of tipping vehicles, where there is no supplementary under frame to distribute the load, the pivot brackets for rearward-tipping bodies shall be located as near as possible to the rear spring brackets to minimize additional bending stresses on the chassis frame during tipping....\n",
      "\n",
      "--- Row 280 ---\n",
      "Text: The table below contains the requirements or a group of requirements in the field of passive safety, already adopted by the World Forum and included into UN Regulations. For any requirement or group o\n",
      "References found: ['paragraphs 8.6. and 8.7.', 'paragraphs 8.14. to 8.17.']\n",
      "❌ Missed (False Negatives):\n",
      "  - paragraph 8.9.: 8.9. Door latches and door retention components Direction of operation of inside door handles Manufa...\n",
      "  - paragraph 8.6.: 8.6. External projections...\n",
      "❌ Incorrect Predictions (False Positives):\n",
      "  - paragraph 8.16.11.: 8.16.11. In the case of tank-vehicles, where outrigger brackets are used to fasten the tank to the chassis of the vehicle, the vertical face of the brackets shall not be less in height than the depth of the chassis frame to which they are attached....\n",
      "  - paragraph 8.16.12.: 8.16.12. In the case of tipping vehicles, where there is no supplementary under frame to distribute the load, the pivot brackets for rearward-tipping bodies shall be located as near as possible to the rear spring brackets to minimize additional bending stresses on the chassis frame during tipping....\n",
      "\n",
      "--- Row 299 ---\n",
      "Text: 8.1.2.1.2. The performances indicated in paragraphs 8.1.2.1.1.1. and 8.1.2.1.1.2. above shall be checked by a type-0 test with the engine disconnected, as described in UN Regulation No. 13, Annex 4, p\n",
      "References found: ['paragraphs 8.1.2.1.1.1. and 8.1.2.1.1.2.', 'Annex 4', 'Annex 4']\n",
      "❌ Missed (False Negatives):\n",
      "  - paragraph 8.1.2.1.1.1.: 8.1.2.1.1.1. In a combination of which at least one component is used for the carriage of passengers...\n",
      "  - paragraph 8.1.2.1.1.2.: 8.1.2.1.1.2. In other combinations....\n",
      "❌ Incorrect Predictions (False Positives):\n",
      "  - Annex 4: Annex 4 - Appendix 4 Housekeeping...\n",
      "\n",
      "--- Row 302 ---\n",
      "Text: 8.1.2.2.1.1. In an emergency manoeuvre, the time elapsing between the moment when the control begins to be actuated and the moment when the braking force on the least favourably placed axle reaches th\n",
      "References found: ['Annex 4', 'paragraph 4.1.1.']\n",
      "❌ Incorrect Predictions (False Positives):\n",
      "  - Annex 4: Annex 4 - Appendix 4 Housekeeping...\n",
      "\n",
      "--- Row 307 ---\n",
      "Text: 8.1.3.1.2. If the respective performances of the service and emergency braking devices are at least equal to 90 per cent of the performances prescribed in UN Regulation No. 13, Annex 4, paragraph 2.3.\n",
      "References found: ['Annex 4', 'paragraph 2.3.2.']\n",
      "❌ Incorrect Predictions (False Positives):\n",
      "  - paragraph 2.3.2.: 2.3.2. \"Category N2\": Vehicles used for the carriage of goods and having a maximum mass exceeding 3,500 kg but not exceeding 12,000 kg....\n",
      "  - Annex 4: Annex 4 - Appendix 4 Housekeeping...\n",
      "\n",
      "--- Row 312 ---\n",
      "Text: 8.1.3.3. The performance required under paragraphs 8.1.3.1., 8.1.3.2.2. and 8.1.3.2.3. may be verified by methods and at speeds different from those prescribed for new vehicles and combinations of new\n",
      "References found: ['paragraphs 8.1.3.1.']\n",
      "❌ Missed (False Negatives):\n",
      "  - paragraph 8.1.3.1.: 8.1.3.1. A combination of vehicles, where both the motor vehicle and the trailer have been in use, m...\n",
      "  - paragraph 8.1.3.2.3.: 8.1.3.2.3. For the combination as a whole, the above provisions shall be met (see paragraph 8.1.3.1....\n",
      "\n",
      "--- Row 324 ---\n",
      "Text: 8.5.1. It is recommended to apply the requirements of the UN Regulations listed in the table of paragraph 6., rows A, B and C.\n",
      "References found: ['paragraph 6.']\n",
      "❌ Missed (False Negatives):\n",
      "  - paragraph 6.: 6. Requirements for the protection of the environment...\n",
      "❌ Incorrect Predictions (False Positives):\n",
      "  - paragraph 6.: 6. Appendices content Appendix 1 shows the historical development of on-road and non-road emission standards and fuel quality (based on CEN standards). Appendix 2 details the fuel parameters aligned with the progression of the UN emission standards that require the use of more advanced exhaust after-treatment control technology that are affected by market fuel quality. Appendix 3 shows the correlation between the series of UN Regulations Nos. 83, 49 and 96 and the parallel Euro standards. Appendix 4 indicates a guideline document on good practice for fuel housekeeping....\n"
     ]
    }
   ],
   "source": [
    "def show_prediction_errors(df: pd.DataFrame, id_to_text: Dict[str, str], max_examples: int = 3):\n",
    "    \"\"\"Show examples of prediction errors for debugging.\"\"\"\n",
    "    count = 0\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if count >= max_examples:\n",
    "            break\n",
    "            \n",
    "        true_ids = set(row[\"targetIds\"])\n",
    "        pred_ids = set(row[\"targetIdsPredicted\"])\n",
    "        fp = pred_ids - true_ids  # False positives\n",
    "        fn = true_ids - pred_ids  # False negatives\n",
    "\n",
    "        if fp or fn:  # Only show errors\n",
    "            print(f\"\\n--- Row {idx} ---\")\n",
    "            print(f\"Text: {row['text'][:200]}\")\n",
    "            print(f\"References found: {row['references']}\")\n",
    "            \n",
    "            if fn:\n",
    "                print(\"❌ Missed (False Negatives):\")\n",
    "                for id_ in list(fn)[:2]:  # Show only first 2\n",
    "                    ref_text = id_to_text.get(id_, '[Unknown]')\n",
    "                    textual_id = generate_textual_id(ref_text)\n",
    "                    print(f\"  - {textual_id}: {ref_text[:100]}...\")\n",
    "            \n",
    "            if fp:\n",
    "                print(\"❌ Incorrect Predictions (False Positives):\")\n",
    "                for id_ in list(fp)[:2]:  # Show only first 2\n",
    "                    ref_text = id_to_text.get(id_, '[Unknown]')\n",
    "                    textual_id = generate_textual_id(ref_text)\n",
    "                    print(f\"  - {textual_id}: {ref_text[:1000]}...\")\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "# Create ID to text mapping for error analysis\n",
    "id_to_text = dict(zip(df_eval['id'], df_eval['text']))\n",
    "\n",
    "# Show sample errors\n",
    "show_prediction_errors(df_eval, id_to_text, max_examples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_application",
   "metadata": {},
   "source": [
    "## Apply to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "apply_to_test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 298 test paragraphs\n",
      "Predictions generated for 17 paragraphs\n",
      "\n",
      "Text: 2.14. \"Sufficient nominal Peak Braking Coefficient (PBC)\": means a road surface friction coefficient of: (a) 0.9, when measured using the American Society for Testing and Materials (ASTM) of E1136-19 standard reference test tyre in accordance with ASTM Method E1337-19 at a speed of 40 mph; (b) 1.017, when measured using either: (i) The American Society for Testing and Materials (ASTM) of F2493-20 standard reference test tyre in accordance with ASTM Method E1337‑19 at a speed of 40 mph; or (ii) The k-test method specified in Appendix 2 to Annex 6 of UN Regulation No. 13-H. (c) The required value to permit the design maximum deceleration of the relevant vehicle, when measured using the k-test method in Appendix 2 to Annex 13 of UN Regulation No. 13....\n",
      "References: ['Annex 6', 'Annex 13']\n",
      "Predicted IDs: 1 items\n",
      "\n",
      "Text: 4.3. Notice of approval or of refusal or withdrawal of approval pursuant to this Regulation shall be communicated to the Contracting Parties to the Agreement which apply this Regulation by means of a form conforming to the model in Annex 1 and documentation supplied by the applicant being in a format not exceeding A4 (210 × 297mm), or folded to that format, and on an appropriate scale or electronic format....\n",
      "References: ['Annex 1']\n",
      "Predicted IDs: 1 items\n",
      "\n",
      "Text: 4.4. There shall be affixed, conspicuously and in a readily accessible place specified on the approval form, to every vehicle conforming to a vehicle type approved under this Regulation, an international approval mark conforming to the model described in Annex 2, consisting of:...\n",
      "References: ['Annex 2']\n",
      "Predicted IDs: 1 items\n"
     ]
    }
   ],
   "source": [
    "def process_test_data(df_test: pd.DataFrame, textual_to_id: Dict[str, str]) -> pd.DataFrame:\n",
    "    \"\"\"Apply the same processing pipeline to test data.\"\"\"\n",
    "    df_test = df_test.copy()\n",
    "    \n",
    "    # Extract textual IDs and references\n",
    "    df_test['textualId'] = df_test['text'].apply(generate_textual_id)\n",
    "    df_test['references'] = df_test['text'].apply(extract_references)\n",
    "    \n",
    "    # Match references to IDs\n",
    "    df_test['targetIdsPredicted'] = df_test['references'].apply(\n",
    "        lambda refs: find_matching_ids(refs, textual_to_id)\n",
    "    )\n",
    "    \n",
    "    return df_test\n",
    "\n",
    "# Process test data\n",
    "df_test_processed = process_test_data(df_test, textual_to_id)\n",
    "\n",
    "print(f\"Processed {len(df_test_processed)} test paragraphs\")\n",
    "print(f\"Predictions generated for {df_test_processed['targetIdsPredicted'].apply(len).gt(0).sum()} paragraphs\")\n",
    "\n",
    "# Show sample results\n",
    "sample_with_predictions = df_test_processed[df_test_processed['targetIdsPredicted'].apply(len) > 0].head(3)\n",
    "for _, row in sample_with_predictions.iterrows():\n",
    "    print(f\"\\nText: {row['text']}...\")\n",
    "    print(f\"References: {row['references']}\")\n",
    "    print(f\"Predicted IDs: {len(row['targetIdsPredicted'])} items\")\n",
    "\n",
    "# Save processed test data\n",
    "df_test_processed.to_csv(\"test_data_with_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b2db9e",
   "metadata": {},
   "source": [
    "## Points for Improvement\n",
    "\n",
    "### Current Achievement\n",
    "- **Time Investment**: 3-4 hours for rule-based solution\n",
    "- **Cost**: Zero (vs. paid ML/API solutions)\n",
    "- **Accuracy**: ~94-95% with simple regex patterns\n",
    "- **Approach**: Practical, explainable, and debuggable\n",
    "\n",
    "### Technical Improvements\n",
    "\n",
    "#### 1. Duplicate Paragraph Numbers\n",
    "- **Issue**: Multiple paragraphs with same number exist in document (e.g., two different \"paragraph 6.\")\n",
    "- **Example**:\n",
    "❌ Missed: paragraph 6. → \"6. Requirements for the protection of the environment...\"\n",
    "❌ False Positive: paragraph 6. → \"6. Appendices content Appendix 1 shows...\"\n",
    "\n",
    "#### 2. Cross-Document Reference Handling\n",
    "- **Issue**: References to UN Regulations (e.g., 'UN Regulation No. 13, Annex 4') not resolved\n",
    "- **Solution**: Build cross-document mapping or external document database\n",
    "- **Impact**: Handle regulatory cross-references better\n",
    "\n",
    "#### 3. Local LLM Implementation\n",
    "- **Approach**: Deploy local LLM (Llama 3, Mixtral, etc.) instead of paid APIs\n",
    "- **Benefits**:\n",
    "  - **Privacy**: No data sent to external services\n",
    "  - **Cost**: One-time setup vs. per-request pricing  \n",
    "  - **Customization**: Fine-tune on legal document patterns\n",
    "  - **Contextual Understanding**: Better handling of ambiguous references\n",
    "\n",
    "### Data Quality Issues\n",
    "\n",
    "#### 1. Training Annotation Errors\n",
    "- **Issue**: Ground truth labels might be inconsistent or incorrect\n",
    "- **Example**: Text mentions \"paragraphs 2.8.2. and 2.8.3.\" but system finds `['paragraphs 2.8.2. and 2.8.3.']` - this should be a **correct match**, not a false negative\n",
    "- **Impact**: Evaluation metrics may be artificially low due to annotation errors\n",
    "- **Solution**: \n",
    "  - Manual review of \"false negatives\" to identify annotation mistakes\n",
    "  - Re-annotate subset of data for quality assessment\n",
    "  - Use multiple annotators with inter-annotator agreement scoring\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "certivity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
